"""–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–æ–≤."""
import json
import os
from datetime import datetime
from pathlib import Path

TOKEN_LOG_FILE = Path("/root/.openclaw/workspace/projects/diet-bot-v2/logs/token_usage.jsonl")

# –¶–µ–Ω—ã –ø—Ä–∏–º–µ—Ä–Ω—ã–µ (–∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤)
PRICING = {
    "openrouter/moonshotai/kimi-k2.5": {"input": 0.8, "output": 2.0},
    "gpt-4o-mini": {"input": 0.15, "output": 0.6},
}


def ensure_log_dir():
    """–°–æ–∑–¥–∞—ë—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ."""
    TOKEN_LOG_FILE.parent.mkdir(parents=True, exist_ok=True)


def log_token_usage(
    operation: str, model: str, input_tokens: int, output_tokens: int, user_id: int = None
) -> dict:
    """–õ–æ–≥–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤.

    Args:
        operation: —Ç–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏ (food_lookup, photo_analysis, etc)
        model: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        input_tokens: —Ç–æ–∫–µ–Ω—ã –Ω–∞ –≤—Ö–æ–¥
        output_tokens: —Ç–æ–∫–µ–Ω—ã –Ω–∞ –≤—ã—Ö–æ–¥
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö
    """
    ensure_log_dir()

    # –†–∞—Å—á—ë—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    prices = PRICING.get(model, {"input": 1.0, "output": 3.0})
    input_cost = (input_tokens / 1_000_000) * prices["input"]
    output_cost = (output_tokens / 1_000_000) * prices["output"]
    total_cost = input_cost + output_cost

    entry = {
        "timestamp": datetime.now().isoformat(),
        "operation": operation,
        "model": model,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_tokens": input_tokens + output_tokens,
        "cost_usd": round(total_cost, 6),
        "user_id": user_id,
    }

    # –î–æ–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
    with open(TOKEN_LOG_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    return entry


def get_daily_stats() -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ —Å–µ–≥–æ–¥–Ω—è."""
    if not TOKEN_LOG_FILE.exists():
        return {"total_tokens": 0, "total_cost": 0, "operations": 0}

    today = datetime.now().strftime("%Y-%m-%d")
    total_tokens = 0
    total_cost = 0
    operations = 0

    with open(TOKEN_LOG_FILE, "r", encoding="utf-8") as f:
        for line in f:
            try:
                entry = json.loads(line.strip())
                if entry["timestamp"].startswith(today):
                    total_tokens += entry["total_tokens"]
                    total_cost += entry["cost_usd"]
                    operations += 1
            except:
                continue

    return {
        "total_tokens": total_tokens,
        "total_cost": round(total_cost, 4),
        "operations": operations,
    }


def format_cost_report(stats: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö."""
    return (
        f"üìä –¢–æ–∫–µ–Ω—ã —Å–µ–≥–æ–¥–Ω—è:\n"
        f"–ó–∞–ø—Ä–æ—Å–æ–≤: {stats['operations']}\n"
        f"–¢–æ–∫–µ–Ω–æ–≤: {stats['total_tokens']:,}\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å: ${stats['total_cost']:.4f}"
    )


def estimate_tokens(text: str) -> int:
    """–û—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ).

    –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ: ~1.5 —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —Å–ª–æ–≤–æ, ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω.
    """
    if not text:
        return 0

    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: 1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ/–∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    char_count = len(text)
    return max(1, char_count // 4)


def log_chat_interaction(
    user_message: str, assistant_response: str, model: str = "openrouter/moonshotai/kimi-k2.5"
) -> dict:
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.

    Args:
        user_message: —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        assistant_response: –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        model: –º–æ–¥–µ–ª—å

    Returns:
        dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö
    """
    input_tokens = estimate_tokens(user_message)
    output_tokens = estimate_tokens(assistant_response)

    return log_token_usage(
        operation="chat_session",
        model=model,
        input_tokens=input_tokens,
        output_tokens=output_tokens,
        user_id=310010786,  # –¢–≤–æ–π ID
    )
